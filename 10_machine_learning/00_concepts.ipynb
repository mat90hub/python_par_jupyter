{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les concepts du *machine learning*.\n",
    "\n",
    "Ces notes ont été prises à partir de la video du site de [Machine Learnia](https://www.youtube.com/watch?v=K9z0OD22My4&list=PLO_fdPEVlfKqUF5BPKjGSh7aV9aBshrpY&index=2) qu'il est recommandé de visionner. Il s'agit de clarifier le vocabulaire (souvent anglais) et les concepts qui sous-tendent les applications d'apprentissage automatique (*machine learning* en anglais)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le jeu de données (*dataset*)\n",
    "\n",
    "Les données collectées sont organisées dans des tables ayant toujours la même structure :\n",
    "- chaque ligne correspond à un enregistrement (il y en a `m`);\n",
    "- chaque colonne correspond à une des caractéristiques de ces enregistrements (*feature* en anglais). \n",
    "Dans les problèmes d'apprentissage automatique, une de ces caractéristiques est identifiée comme celle qu'on veut pouvoir prédir à partir des autres. \n",
    "\n",
    "Dans l'apprentissage automatique supervisé, le jeu de données qui servira à l'apprentissage de notre machine, contient cette colonne de caractéristique à prédire. On l'isole du jeu de données et cela constitue la cible (*target*) de notre échantillon d'apprentissage : pour chacun des enregistrements, le modèle aura été entraîné à retrouver la composante cible correspondante. Cette cible est notée conventionnement `y`. Il s'agit donc d'un vecteur colonne ayant pour taille le nombre `m` d'enregistrements réalisés. Le reste des données auront `n` caractéristiques. Ce sera une table de `m` lignes et `n` colonne, usuellement représentée par une matrice `X`.\n",
    "\n",
    "Les éléments de la matrice `X` seront notés $x_i^{(j)}$, $i$ étant le numéro de ligne, c'est-à dire le numéro d'enregistrement, et $j$ le numéro de colonne, c'est-à dire le numéro de la caractéristique observée (*feature*). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici ci-dessous un exemple de `dataset`que j'affiche sous forme de table en utilisant l'extension [tabulate](https://github.com/astanin/python-tabulate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╭────────┬─────────┬─────────────╮\n",
      "│ Prix   │ Surface │ code postal │\n",
      "├────────┼─────────┼─────────────┤\n",
      "│ 313000 │ 90      │ 9500        │\n",
      "├────────┼─────────┼─────────────┤\n",
      "│ 720000 │ 110     │ 93000       │\n",
      "├────────┼─────────┼─────────────┤\n",
      "│ 250000 │ 40      │ 44500       │\n",
      "├────────┼─────────┼─────────────┤\n",
      "│ 290000 │ 60      │ 67000       │\n",
      "├────────┼─────────┼─────────────┤\n",
      "│ 190000 │ 50      │ 59300       │\n",
      "╰────────┴─────────┴─────────────╯\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "titre = np.array(['Prix', 'Surface', 'code postal']).reshape(1,3)\n",
    "y = np.array([313000, 720000, 250000, 290000, 190000]).reshape(5,1)\n",
    "X = np.array([[90,9500],[110,93000], [40, 44500], [60,67000], [50, 59300]])\n",
    "\n",
    "print(tabulate(np.concatenate((titre, np.concatenate((y,X), axis=1)), axis=0), tablefmt='rounded_grid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dans cet exemple, `y` est les prix observés des appartements, `X` est leurs autres caractéritiques, ici la surface et le code postal.\n",
    "\n",
    "Le *dataset* est le couple `(X,y)`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le modèle\n",
    "\n",
    "Le modèle est une fonction qui à partir des caractéristiques observées $X$ fera une prévision qu'on espère être proche de la cible $y$. Ce modèle sera paramétré par une liste de paramètre $\\theta$.\n",
    "\n",
    "$$ y = f_\\theta(x) = F(x, \\theta)$$\n",
    "\n",
    "L'objectif sera de faire apprendre notre modèle pour qu'à partir des caractéristiques observées, il obtienne un résultat proche de la cible que nous cherchons.\n",
    "\n",
    "\n",
    "## La fonction coût\n",
    "\n",
    "Pour déterminer si notre modèle donne des résultats *proches* de notre cible, on introduit une fonction coût (ou d'erreur). Cette fonction donne un calcul de l'écart des prévisions du modèle avec la cible qu'il aurait fallut atteindre. L'objectif est de déterminer les  paramètres pour lesquels, la fonction de coût est minimum.\n",
    "\n",
    "Une fonction de coût classique est l'écart quadratique :\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m \\big(y - F(X, \\theta)\\big)^2 $$\n",
    "\n",
    "Mais on pourra trouver d'autre forme. Par exemple, la somme des valeurs absolues aurait pu être utilisée comme fonction coût, mais n'étant pas dérivable en 0, cela perturbe les calculs à venir.\n",
    "\n",
    "\n",
    "## Problème de régression ou de classification\n",
    "\n",
    "Quand la cible peut prendre toutes les valeurs d'un domaine continu, le problème est un problème de régression. Quand elle ne peut prendre qu'un nombre fini de valeurs, alors il s'agit d'un problème de classification, que nous détaillerons par la suite.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemple sur la régression linéaire\n",
    "\n",
    "La régression a l'avantage d'être simple pour bien illustrer les concepts qui viennent d'être présentés. Le chaine de machine learnia illustre cet exemple, mais on trouve aussi d'autres présentations comme le blog de Thibault [Miximum](https://www.miximum.fr/blog/premiers-tests-avec-le-machine-learning/) présente la construction de cet algorithme du gradient. On trouve aussi plus de détails sur cet algorithme sur la page [Wikipedia](https://fr.wikipedia.org/wiki/Algorithme_du_gradient).\n",
    "\n",
    "Le *dataset* est constitués de points de coordonnées (x,y), les ordonnées y sont nos cibles et les points x sont les m observations de notre unique caractéristique (*feature*).\n",
    "\n",
    "Dans une régression linéaire, le modèle est une fonction de la forme: $ y = \\theta_0 + \\theta_1 x$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quand nous estimons les $y$ avec cette fonction linéaire, nous faisons une erreur par rapport à notre nuage de point initial. Cette erreur peut être quantifiée au travers d'une fonction de coût qui a cette expression.\n",
    "\n",
    "\n",
    "$$ J(\\theta_0, \\theta_1) = \\frac{1}{2m} \\sum_{i=1}^m \\left[ \\theta_0 + \\theta_1 \\times x^{(i)} - y^{(i)} \\right]^2$$\n",
    "\n",
    "L'objectif sera de rechercher la coût minimum en fonction des paramètres $\\theta_0, \\theta_1$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une représentation graphique de la fonction $J$, pour laquelle les coordonnées usuelles $(x,y)$ ont été remplacées par ces deux paramètres $(\\theta_0,\\theta_1)$. La valeur de $J$ peut alors être représentée par une couleur ou une hauteur sur un troisième axe fictif comme le montre la figure ci-dessous.\n",
    "\n",
    "![fonction à deux paramètres](./img/RQKM5OWWMA.png)\n",
    "\n",
    "Nous voyons bien que cette fonction est convexe avec un minimum unique. Le couple de paramètres que nous cherchons $\\theta = (\\theta_0,\\theta_1)$ se trouve au minimum de cette fonction $J$. \n",
    "\n",
    "Cette représentation de la valeur de $J$ comme une hauteur sur un troisième axe imaginaire est souvent plus parlante. On imagine marcher sur cette surface en plein brouillard. Pour trouver le fond de cette vallée, nous nous basons sur un pas réguliers : tant que nous descendons, c'est que nous avançons vers le minimum. Si cette descente se ralentie, il est probable que nous approchons de la solution. Si tout d'un coup nous remontons, c'est que nous avons sûrement dépassé ce minimum. C'est en termes imagés le principe de l'algorithme du gradient."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On rappelle que le gradient de la fonction $J$ s'écrit de la manière suivante\n",
    "\n",
    "$$ \\overrightarrow{\\nabla J} =\\frac{\\partial J}{\\partial \\theta_0} \\overrightarrow{u_{\\theta_0}} + \\frac{\\partial J}{\\partial \\theta_1} \\vec{u_{\\theta_1}}$$\n",
    "\n",
    "Le gradient est un vecteur dont la dimension est égale au nombre de paramètre et qui designe la ligne de plus grande pente, dans le sens de la montée."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À chaque pas, il faut choisir une direction de descente et [on montre qu'une solution est de choisir l'inverse du gradient comme direction de descente](https://fr.wikipedia.org/wiki/Direction_de_descente). Si on reprend l'image de notre surface, le gradient est la projection sur la carte de la direction « où cela monte ». Les gradients sont d'ailleurs des vecteurs perpendiculaires aux lignes de niveau. En prenant la direction inverse, on est donc à peu près sûr de descendre, comme le montre l'image ci-dessous.\n",
    "\n",
    "![chemin](./img/Gradient_descent.png)\n",
    "\n",
    "En pratique, on multiplie cette direction par un coefficient $\\alpha$, qui représente la vitesse à laquelle on veut descendre. Ce coefficient est aussi à optimiser. Un pas important permet de descendre plus vite, mais peut aussi nous faire manquer le minimum exacte.\n",
    "\n",
    "En clair, on fera les pas suivants.\n",
    "\n",
    "$$\n",
    "\\theta_0 \\rightarrow \\theta_0 - \\alpha \\times \\frac{\\partial J}{\\partial \\theta_0}\n",
    "\\quad ; \\quad\n",
    "\\theta_1 \\rightarrow \\theta_1 - \\alpha \\times \\frac{\\partial J}{\\partial \\theta_1}\n",
    "$$\n",
    "\n",
    "(La méthode du gradient n'est pas la seule méthode pour trouver la meilleure pente. D'autres méthodes jugées plus efficaces existent comme la [méthode BFGS](https://en.wikipedia.org/wiki/Limited-memory_BFGS).)\n",
    "\n",
    "On rappelle ici l'expression de la fonction de coût.\n",
    "\n",
    "$$ J(\\theta_0, \\theta_1) = \\frac{1}{2m} \\sum_{i=1}^m \\left[ \\theta_0 + \\theta_1 \\times x^{(i)} - y^{(i)} \\right]^2$$\n",
    "\n",
    "Son minimum est atteint quand le gradient devient nul.\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\frac{\\partial{J}}{\\partial{\\theta_0}} &= \\frac{1}{m} \\sum_{i=1}^m \\large(\\theta_0+ \\theta_1 x^{(i)} - y^{(i)}\\large) &= 0 \\\\\n",
    "\\frac{\\partial{J}}{\\partial{\\theta_1}} &= \\frac{1}{m} \\sum_{i=1}^m x^{(i)} \\large(\\theta_0+ \\theta_1 x^{(i)} - y^{(i)}) &= 0 \\\\\n",
    "\\end{align*}$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour bénéficier des capacités de calcul matriciel des outils de calcul (comme le langage Python), on écrit les équations précédantes sous une forme matricielle :\n",
    "\n",
    "$$ F = X \\times \\theta $$\n",
    "\n",
    "$F$ est un vecteur colonne de $m$ éléments qui représente l'estimation du vecteur cible $Y$. \n",
    "\n",
    "$\\theta$ est le vecteur colonne de nos deux paramètres (a,b). X est une matrice contenant nos m observations en première colonne et des 1 en seconde colonne, de telle sorte que la multiplication matricielle de l'un par l'autre donne les $m$ équations qu'on veut obtenir : c'est une matrice de taille (m,2) multiplié par $\\theta$ de taille (2,1).\n",
    "\n",
    "$$\n",
    "\\left[ \\begin{array}{c}f^{(1)}\\\\f^{(2)}\\\\\\dots\\\\f^{(m)}\\\\\\end{array}\\right]\n",
    "=\n",
    "\\left[ \\begin{array}{cc}1 & x^{(1)}\\\\1 & x^{(2)}\\\\\\dots & \\dots \\\\1 & x^{(m)}\\\\\\end{array}\\right]\n",
    "\\times\n",
    "\\left[\\begin{array}{c}\\theta_0 \\\\ \\theta_1 \\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Et s'il y avait eu plus de caractéristiques (n), X aurait eu n+1 colonnes : on ajoute toujours une colonne de biais à nos données pour représenter ce reste. Voici l'exemple avec deux caractéristiques.\n",
    "\n",
    "$$\n",
    "\\left[ \\begin{array}{c}f^{(1)}\\\\f^{(2)}\\\\\\dots\\\\f^{(m)}\\\\\\end{array}\\right]\n",
    "=\n",
    "\\left[ \\begin{array}{ccc}1 & x_1^{(1)} & x_2^{(1)}\\\\ 1 & x_1^{(2)} & x_2^{(2)}\\\\\\dots & \\dots & \\dots\\\\ 1 & x_1^{(m)} & x_2^{(m)}\\\\\\end{array}\\right]\n",
    "\\times\n",
    "\\left[\\begin{array}{c}\\theta_0 \\\\ \\theta_1 \\\\ \\theta_2 \\end{array}\\right]\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En revenant au cas simple d'une seule caractéristiques, nous pouvons aussi transformer l'expression de la fonction de coût pour lui donner une forme matricielle.\n",
    "\n",
    "$$\\begin{align*}\n",
    "J(\\theta_0,\\theta_1) &= \\frac{1}{2m}\\sum_{i=1}^m (\\theta_0 + \\theta_1 x^{(i)} - y^{(i)})^2 \\\\\n",
    "J(\\theta) &= \\frac{1}{2m} \\sum(X\\times\\theta -Y)^2\n",
    "\\end{align*}$$\n",
    "\n",
    "Et on pourra vérifier que la forme matricielle resterait inchangée en augmentant le nombre de caractéristiques."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même, l'expression du gradient est aussi simple sous sa forme matricielle.\n",
    "\n",
    "$$ \\frac{\\partial{J}(\\theta)}{\\partial{\\theta}} = \\frac{1}{m} X^T \\times (X\\times\\theta -  Y)$$\n",
    "\n",
    "\n",
    "En effet, si on décompose, nous avons vu le produit matriciel (noté ici '$\\times$')\n",
    "\n",
    "$$\n",
    "X \\times \\theta - Y\n",
    "=\n",
    "\\left[ \\begin{array}{cc}1 & x^{(1)}\\\\ 1 & x^{(2)}\\\\\\dots & \\dots \\\\ 1 & x^{(m)}\\\\\\end{array}\\right]\n",
    "\\times\n",
    "\\left[\\begin{array}{c} \\theta_0 \\\\ \\theta_1 \\end{array}\\right]\n",
    "- \n",
    "\\left[ \\begin{array}{c} y^{(1)}\\\\y^{(2)}\\\\ \\dots \\\\y^{(m)} \\\\\\end{array}\\right]\n",
    "=\n",
    "\\left[\\begin{array}{c} \\theta_0 + \\theta_1 x^{(1)} - y^{(1)}\\\\ \\theta_0 + \\theta_1 x^{(2)} - y^{(2)}\\\\ \\dots \\\\ \\theta_0 + \\theta_1 x^{(m)} - y^{(m)} \\\\ \\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Même si on introduisait plus de caratéristiques (mais avec des matrices explosant en taille), $X$ est toujours la matrice à m lignes et (n+1) colonnes, $\\theta$ la matrice colonne à (n+1) éléments (toujours avec ce biais à rajouter). La multiplication matricielle donne donc une matrice de m éléments et une colonne, qu'on peut ajouter avec la matrice colonne $Y$.\n",
    "\n",
    "Sur l'élément extérieur, l'opération est la suivante.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{J}(\\theta)}{\\partial{\\theta}} =  \n",
    "\\left[\\begin{array}{c}\\frac{\\partial{J}}{\\partial{\\theta_0}}\\\\[0.2cm]\\frac{\\partial{J}}{\\partial{\\theta_1}}\\end{array}\\right]\n",
    "= \\frac{1}{m}\n",
    "\\left[\\begin{array}{llcl}1 & 1 & \\dots & 1 \\\\ x^{(1)} & x^{(2)} & \\dots & x^{(m)}\\\\ \\end{array}\\right]\n",
    "\\times\n",
    "\\left[\\begin{array}{c}\\theta_0 + \\theta_1 ax^{(1)} - y^{(1)}\\\\\\theta_0 + \\theta_1 ax^{(2)} - y^{(2)}\\\\ \\dots \\\\ \\theta_0 + \\theta_1 ax^{(m)} - y^{(m)} \\\\ \\end{array}\\right]\n",
    "$$\n",
    "\n",
    "La transposée de $X$ est une matrice $(n+1, m)$ qu'on multiplie avec un membre de dimension $(m,1)$ pour obtenir donc les $(n+1)$ équations donnant les paramètres $\\theta$ recherchés."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode de descente du gradient vue plus haut pourra aussi s'écrire sous forme matricielle de la façon suivante.\n",
    "\n",
    "$$ \\theta \\leftarrow \\theta -\\alpha \\frac{\\partial{J}}{\\partial{\\theta}}$$\n",
    "\n",
    "$\\theta$ et J sont tous les deux de dimensions (n+1,1)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Généralisation à une régression polynomiale\n",
    "\n",
    "L'équation matricielle permettra de résoudre le problème.\n",
    "\n",
    "$$ F = X\\cdot \\theta $$\n",
    "\n",
    "Le modèle cherché est de la forme:\n",
    "\n",
    "$$f(x) = ax^2 + bx +c$$\n",
    "\n",
    "c'est-à dire trois paramètres.\n",
    "\n",
    "La matrice $X$ aura en première colonne les carrés des observation, en deuxième colonne les valeurs simples et en troisième les 1. Le vecteur colonne $\\theta$ sera constitué de a,b,c.\n",
    "\n",
    "(pour plus des explications plus détaillées, revoir la [vidéo](https://www.youtube.com/watch?v=8Y3r7F47Xfo&list=PLO_fdPEVlfKqUF5BPKjGSh7aV9aBshrpY&index=6))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation de l'échantillon\n",
    "\n",
    "Il peut y a avoir plusieurs pré-traitement à faire à un échantillon. On voit bien que si nos courbes de niveau vues plus haut sont complètement déformées avec une caractéristiques ayant des valeurs d'un tout autre ordre de grandeur que l'autre, on risque d'égarer la recherche.\n",
    "\n",
    "Pour éviter aussi les cas particuliers ou les deux paramètres auraient des ordres de grandeur totalement différent, on peut aussi normaliser les données $(x_i)_i$ et $(y_i)_i$. Cela se ferait de la manière suivante."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le module Scikit learn propose la commande [normalize](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html#sklearn.preprocessing.normalize) pour faire cette normalisation directement."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Évaluer la convergence de la méthode\n",
    "\n",
    "Dans les applications numériques qui suivent, nous verrons comment présenter une courbe qui montre la vitesse de convergence de la solution. Ceci sert en particulier pendant la recherche des bons paramètres qui font converger ou non la méthode du gradient (le nombre de pas et la vitesse de descente).\n",
    "\n",
    "Il existe aussi un coefficient dit de détermination qui a la forme suivante.\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum \\big(y-f(x)\\big)^2}{\\sum (y - \\overline{x})^2}$$\n",
    "\n",
    "Il donne aussi une vision synthétique de la qualité de notre modélisation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
