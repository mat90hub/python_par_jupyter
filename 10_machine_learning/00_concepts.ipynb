{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les concepts du *machine learning*.\n",
    "\n",
    "Ces notes ont été prises à partir de la video du site de [Machine Learnia](https://www.youtube.com/watch?v=K9z0OD22My4&list=PLO_fdPEVlfKqUF5BPKjGSh7aV9aBshrpY&index=2) qu'il est recommandé de visionner. Il s'agit de clarifier le vocabulaire (souvent anglais) et les concepts qui sous-tendent les applications d'apprentissage automatique (*machine learning* en anglais)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le jeu de données (*dataset*)\n",
    "\n",
    "Les données collectées sont organisées dans des tables ayant toujours la même structure :\n",
    "- chaque ligne correspond à un enregistrement (il y en a `m`);\n",
    "- chaque colonne correspond à une des caractéristiques de ces enregistrements (*feature* en anglais). \n",
    "Dans les problèmes d'apprentissage automatique, une de ces caractéristiques est identifiée comme celle qu'on veut pouvoir prédir à partir des autres. \n",
    "\n",
    "Dans l'apprentissage automatique supervisé, le jeu de données qui servira à l'apprentissage de notre machine, contient cette colonne de caractéristique à prédire. On l'isole du jeu de données et cela constitue la cible (*target*) de notre échantillon d'apprentissage : pour chacun des enregistrements, le modèle aura été entraîné à retrouver la composante cible correspondante. Cette cible est notée conventionnement `y`. Il s'agit donc d'un vecteur colonne ayant pour taille le nombre `m` d'enregistrements réalisés. Le reste des données auront `n` caractéristiques. Ce sera une table de `m` lignes et `n` colonne, usuellement représentée par une matrice `X`.\n",
    "\n",
    "Les éléments de la matrice `X` seront notés $x_i^{(j)}$, $i$ étant le numéro de ligne, c'est-à dire le numéro d'enregistrement, et $j$ le numéro de colonne, c'est-à dire le numéro de la caractéristique observée (*feature*). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici ci-dessous un exemple de `dataset`que j'affiche sous forme de table en utilisant l'extension [tabulate](https://github.com/astanin/python-tabulate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╭────────┬─────────┬─────────────╮\n",
      "│ Prix   │ Surface │ code postal │\n",
      "├────────┼─────────┼─────────────┤\n",
      "│ 313000 │ 90      │ 9500        │\n",
      "├────────┼─────────┼─────────────┤\n",
      "│ 720000 │ 110     │ 93000       │\n",
      "├────────┼─────────┼─────────────┤\n",
      "│ 250000 │ 40      │ 44500       │\n",
      "├────────┼─────────┼─────────────┤\n",
      "│ 290000 │ 60      │ 67000       │\n",
      "├────────┼─────────┼─────────────┤\n",
      "│ 190000 │ 50      │ 59300       │\n",
      "╰────────┴─────────┴─────────────╯\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "titre = np.array(['Prix', 'Surface', 'code postal']).reshape(1,3)\n",
    "y = np.array([313000, 720000, 250000, 290000, 190000]).reshape(5,1)\n",
    "X = np.array([[90,9500],[110,93000], [40, 44500], [60,67000], [50, 59300]])\n",
    "\n",
    "print(tabulate(np.concatenate((titre, np.concatenate((y,X), axis=1)), axis=0), tablefmt='rounded_grid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le *dataset* est le couple `(X,y)`. Dans cet exemple, `y` est le prix observé des appartements, `X` leurs autres caractéristiques, ici réduites à la surface et le code postal. L'objectif est donc d'apprendre à prédire le prix de l'appartement en fonction de ses caractéristiques."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le modèle pour l'apprentissage.\n",
    "\n",
    "Pour établir nos prédictions, nous bâtissons un modèle. Il s'agit d'une fonction prenant en entrée les caractéristiques observées $X$ et qui donne une prévision du prix $y$. \n",
    "Ce modèle n'est pas unique. Quel est celui donnant les meilleurs prédictions ? Pour le déterminer nous identifions dans notre modèle des paramètres caractéristiques, notés par le vecteur $\\Theta = (\\theta_1, \\dots \\theta_n)$.\n",
    "\n",
    "$$ y = f_\\Theta(X) = F(X, \\Theta)$$\n",
    "\n",
    "L'objectif est maintenant de tester notre modèle sur un échantillon d'apprentissage pour lequel on connaît donc les couples $(X,y)$. L'observation de ce modèle doit permettre d'identifier les paramètres $\\Theta$ qui donneront des résultats les plus proches des observations faites sur notre échantillon de d'apprentissage.\n",
    "\n",
    "\n",
    "## La fonction pour l'optimisation.\n",
    "\n",
    "Pour déterminer si un modèle donne des résultats *proches* de nos cibles, on introduit une fonction qui donnera l'écart global. Cette fonction peut être appelée la fonction de coût (mais ici à ne pas confondre avec le prix des appartements qui sont nos cibles), d'autres fois une fonctions d'erreur ou de perte (*loss* en anglais). Cette fonction dooit être continue et dérivable et être minimum si le résultat est parfait et augmenter dans l'autre cas.\n",
    "\n",
    "Une fonction classique qui remplie bien ces propriétés est l'écart quadratique :\n",
    "\n",
    "$$ J(\\Theta) = \\frac{1}{2m} \\sum_{i=1}^m \\big(y - F(X, \\Theta)\\big)^2 $$\n",
    "\n",
    "On pourra trouver d'autre forme, si elle sont plus adaptées au problème posé.\n",
    "\n",
    "\n",
    "## Problème de régression ou de classification.\n",
    "\n",
    "Faisons tout de suite une petite clarification de vocabulaire :\n",
    "- quand la cible peut prendre toutes les valeurs d'un domaine continu, le problème est un problème de **régression** ;\n",
    "- quand elle ne peut prendre qu'un nombre fini de valeurs, alors il s'agit d'un problème de classification.\n",
    "\n",
    "Ce cahier présente un problème de régression. D'autres cahier montreront les sujets de classifications.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemple sur la régression linéaire\n",
    "\n",
    "La régression linéaire a l'avantage d'être simple pour illustrer les concepts qui viennent d'être présentés. Le chaîne de [machine learnia](https://www.youtube.com/watch?v=K9z0OD22My4&list=PLO_fdPEVlfKqUF5BPKjGSh7aV9aBshrpY&index=3) illustre cet exemple, mais on trouve aussi d'autres présentations comme le blog de Thibault [Miximum](https://www.miximum.fr/blog/premiers-tests-avec-le-machine-learning/) qui présente la construction de l'algorithme du gradient. On trouve aussi des détails plus complets sur cet algorithme sur la page [Wikipedia](https://fr.wikipedia.org/wiki/Algorithme_du_gradient).\n",
    "\n",
    "Le *dataset* est constitués de points de coordonnées (x,y), les ordonnées y sont nos cibles (donc un simple scalaire au lieu d'un vecteur de plusieurs données) et les points x sont les m observations de notre unique caractéristique (*feature*).\n",
    "\n",
    "Dans une régression linéaire, le modèle est une fonction de la forme: $ y = \\theta_0 + \\theta_1 x$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quand nous estimons les $y$ avec cette fonction linéaire, nous faisons une erreur par rapport à notre nuage de point initial. Cette erreur peut être quantifiée au travers d'une fonction de coût qui a cette expression.\n",
    "\n",
    "\n",
    "$$\\displaystyle J(\\theta_0, \\theta_1) = \\frac{1}{2m} \\sum_{i=1}^m \\left[ \\theta_0 + \\theta_1 \\times x^{(i)} - y^{(i)} \\right]^2 $$\n",
    "\n",
    "L'objectif sera de rechercher la coût minimum en fonction des paramètres $\\theta_0, \\theta_1$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une représentation graphique de la fonction $J$, pour laquelle les coordonnées usuelles $(x,y)$ ont été remplacées par ces deux paramètres $(\\theta_0,\\theta_1)$. La valeur de $J$ peut alors être représentée par une couleur ou une hauteur sur un troisième axe fictif comme le montre la figure ci-dessous.\n",
    "\n",
    "![fonction à deux paramètres](./img/RQKM5OWWMA.png)\n",
    "\n",
    "Nous voyons bien que cette fonction est convexe avec un minimum unique. Le couple de paramètres que nous cherchons $\\theta = (\\theta_0,\\theta_1)$ se trouve au minimum de cette fonction $J$. \n",
    "\n",
    "Cette représentation de la valeur de $J$ comme une hauteur sur un troisième axe imaginaire est souvent plus parlante. On imagine marcher sur cette surface en plein brouillard. Pour trouver le fond de cette vallée, nous nous basons sur un pas réguliers : tant que nous descendons, c'est que nous avançons vers le minimum. Si cette descente se ralentie, il est probable que nous approchons de la solution. Si tout d'un coup nous remontons, c'est que nous avons sûrement dépassé ce minimum. C'est en termes imagés le principe de l'algorithme du gradient."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On rappelle que le gradient de la fonction $J$ s'écrit de la manière suivante\n",
    "\n",
    "$$\\displaystyle \\overrightarrow{\\nabla J} =\\frac{\\partial J}{\\partial \\theta_0} \\overrightarrow{u_{\\theta_0}} + \\frac{\\partial J}{\\partial \\theta_1} \\vec{u_{\\theta_1}}$$\n",
    "\n",
    "Le gradient est un vecteur dont la dimension est égale au nombre de paramètres et qui désigne la ligne de plus grande pente, dans le sens de la montée."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À chaque pas, il faut choisir une direction de descente et [on montre qu'une solution est de choisir l'inverse du gradient comme direction de descente](https://fr.wikipedia.org/wiki/Direction_de_descente). Si on reprend l'image de notre surface, le gradient est la projection sur la carte de la direction « où cela monte ». Les gradients sont d'ailleurs des vecteurs perpendiculaires aux lignes de niveau. En prenant la direction inverse, on est donc à peu près sûr de descendre, comme le montre l'image ci-dessous.\n",
    "\n",
    "![chemin](./img/Gradient_descent.png)\n",
    "\n",
    "En pratique, on multiplie cette direction par un coefficient $\\alpha$, qui représente la vitesse à laquelle on veut descendre. Ce coefficient est aussi à optimiser. Un pas important permet de descendre plus vite, mais peut aussi nous faire manquer le minimum exacte.\n",
    "\n",
    "En clair, on fera les pas suivants.\n",
    "\n",
    "$$\\displaystyle\n",
    "\\theta_0 \\rightarrow \\theta_0 - \\alpha \\times \\frac{\\partial J}{\\partial \\theta_0}\n",
    "\\quad ; \\quad\n",
    "\\theta_1 \\rightarrow \\theta_1 - \\alpha \\times \\frac{\\partial J}{\\partial \\theta_1}\n",
    "$$\n",
    "\n",
    "(La méthode du gradient n'est pas la seule méthode pour trouver la meilleure pente. D'autres méthodes jugées plus efficaces existent comme la [méthode BFGS](https://en.wikipedia.org/wiki/Limited-memory_BFGS).)\n",
    "\n",
    "On rappelle ici l'expression de la fonction de coût.\n",
    "\n",
    "$$\\displaystyle J(\\theta_0, \\theta_1) = \\frac{1}{2m} \\sum_{i=1}^m \\left[ \\theta_0 + \\theta_1 \\times x^{(i)} - y^{(i)} \\right]^2$$\n",
    "\n",
    "Son minimum est atteint quand le gradient devient nul.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial{J}}{\\partial{\\theta_0}} &= \\frac{1}{m} \\sum_{i=1}^m \\large(\\theta_0+ \\theta_1 x^{(i)} - y^{(i)}\\large)   &= 0\\\\\n",
    "\\frac{\\partial{J}}{\\partial{\\theta_1}} &= \\frac{1}{m} \\sum_{i=1}^m x^{(i)} \\large(\\theta_0+ \\theta_1 x^{(i)} - y^{(i)}) &= 0\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour bénéficier des capacités de calcul matriciel des outils de calcul (comme le langage Python), on écrit les équations précédentes sous une forme matricielle :\n",
    "\n",
    "$\\displaystyle F = X \\circ \\Theta $\n",
    "\n",
    "$F$ est un vecteur colonne de $m$ éléments qui représente l'estimation du vecteur cible $Y$. La multiplication scalaire $\\times$ est remplacée par une multiplication matricielle $\\circ$ qui est ici la loi de composition classique.\n",
    "\n",
    "$\\Theta$ est le vecteur colonne de nos deux paramètres (a,b). X est une matrice contenant nos m observations en première colonne et des 1 en seconde colonne, de telle sorte que la multiplication matricielle de l'un par l'autre donne les $m$ équations qu'on veut obtenir : c'est une matrice de taille (m,2) multiplié par $\\Theta$ de taille (2,1).\n",
    "\n",
    "$$\n",
    "\\left[ \\begin{array}{c}f^{(1)}\\\\f^{(2)}\\\\\\dots\\\\f^{(m)}\\\\\\end{array}\\right]\n",
    "=\n",
    "\\left[ \\begin{array}{cc}1 & x^{(1)}\\\\1 & x^{(2)}\\\\\\dots & \\dots \\\\1 & x^{(m)}\\\\\\end{array}\\right]\n",
    "\\circ\n",
    "\\left[\\begin{array}{c}\\theta_0 \\\\ \\theta_1 \\end{array}\\right]\n",
    "\\quad \\quad \\quad \n",
    "= \\left[ \\begin{array}{cc}\\theta_0 +\\theta_1\\times x^{(1)} \\\\\\theta_0 + \\theta_1\\times x^{(2)}\\\\\\dots \\\\\\theta_0 + \\theta_1 \\times x^{(m)}\\\\\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Et s'il y avait eu plus de caractéristiques (n), X aurait eu n+1 colonnes : on ajoute toujours une colonne de biais à nos données pour représenter ce reste. Voici l'exemple avec deux caractéristiques.\n",
    "\n",
    "$$\n",
    "\\left[ \\begin{array}{c}f^{(1)}\\\\f^{(2)}\\\\\\dots\\\\f^{(m)}\\\\\\end{array}\\right]\n",
    "=\n",
    "\\left[ \\begin{array}{ccc}1 & x_1^{(1)} & x_2^{(1)}\\\\ 1 & x_1^{(2)} & x_2^{(2)}\\\\\\dots & \\dots & \\dots\\\\ 1 & x_1^{(m)} & x_2^{(m)}\\\\\\end{array}\\right]\n",
    "\\circ\n",
    "\\left[\\begin{array}{c}\\theta_0 \\\\ \\theta_1 \\\\ \\theta_2 \\end{array}\\right]\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En revenant au cas simple d'une seule caractéristiques, nous pouvons aussi transformer l'expression de la fonction de coût pour lui donner une forme matricielle.\n",
    "\n",
    "$$\\begin{align*}\n",
    "J(\\theta_0,\\theta_1) &= \\frac{1}{2m}\\sum_{i=1}^m (\\theta_0 + \\theta_1 x^{(i)} - y^{(i)})^2 \\\\\n",
    "J(\\Theta) &= \\frac{1}{2m} \\sum(X\\circ \\Theta -Y)^2\n",
    "\\end{align*}$$\n",
    "\n",
    "Et on pourra vérifier que la forme matricielle resterait inchangée en augmentant le nombre de caractéristiques."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forme assez simple de $J(\\Theta)$ sous sa forme matricielle permet d'exprimer le gradient aussi sous une forme matricielle (ici $X^T$ représente la matrice transposée de $X$):\n",
    "\n",
    "$$ \\frac{\\partial{J}(\\theta)}{\\partial{\\theta}} = \\frac{1}{m} X^T \\circ (X\\circ\\theta -  Y)$$\n",
    "\n",
    "Pour le démontrer, reprenons les termes un à un.\n",
    "\n",
    "$$\n",
    "X \\circ \\theta - Y\n",
    "=\n",
    "\\left[ \\begin{array}{cc}1 & x^{(1)}\\\\ 1 & x^{(2)}\\\\\\dots & \\dots \\\\ 1 & x^{(m)}\\\\\\end{array}\\right]\n",
    "\\circ\n",
    "\\left[\\begin{array}{c} \\theta_0 \\\\ \\theta_1 \\end{array}\\right]\n",
    "- \n",
    "\\left[ \\begin{array}{c} y^{(1)}\\\\y^{(2)}\\\\ \\dots \\\\y^{(m)} \\\\\\end{array}\\right]\n",
    "=\n",
    "\\left[\\begin{array}{c} \\theta_0 + \\theta_1 x^{(1)} - y^{(1)}\\\\ \\theta_0 + \\theta_1 x^{(2)} - y^{(2)}\\\\ \\dots \\\\ \\theta_0 + \\theta_1 x^{(m)} - y^{(m)} \\\\ \\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Si on introduisait plus de caractéristiques à observer ($n$), $X$ deviendrait une matrice à $m$ lignes ($m$ étant le nombre d'observations dans l'échantillon d'apprentissage) et $(n+1)$ colonnes ($n$ étant le nombre d'observation dans un échantillon, ici $1$). $\\Theta$, la matrice des paramètres recherchés serait une matrice colonne à (n+1) éléments (toujours avec ce biais à rajouter). La multiplication matricielle donne donc une matrice de $m$ éléments et $1$ colonne, qu'on peut ajouter avec la matrice colonne $Y$.\n",
    "\n",
    "Multiplions maintenant l'expression précédente par $X^T$:\n",
    "\n",
    "$$\n",
    "\\frac{1}{m}\n",
    "\\left[\\begin{array}{llcl}1 & 1 & \\dots & 1 \\\\ x^{(1)} & x^{(2)} & \\dots & x^{(m)}\\\\ \\end{array}\\right]\n",
    "\\circ\n",
    "\\left[\\begin{array}{c}\\theta_0 + \\theta_1 ax^{(1)} - y^{(1)}\\\\\\theta_0 + \\theta_1 ax^{(2)} - y^{(2)}\\\\ \\dots \\\\ \\theta_0 + \\theta_1 ax^{(m)} - y^{(m)} \\\\ \\end{array}\\right]\n",
    "\\quad = \\quad\n",
    " \\frac{1}{m}\\left[\\begin{array}{l}\n",
    "       \\theta_0 + \\theta_1 ax^{(1)} - y^{(1)} + \\dots \\theta_0 + \\theta_1 ax^{(n)} - y^{(n)} \\\\ \\\\\n",
    "       x^{(1)}\\Big(\\theta_0 + \\theta_1 ax^{(1)} - y^{(1)}\\Big) + \\dots x^{(n)}\\Big(\\theta_0 + \\theta_1 ax^{(n)} - y^{(n)}\\Big) \\\\ \n",
    "      \\end{array}\\right]\n",
    "= \\quad \\left[\\begin{array}{c}\\frac{\\partial{J}}{\\partial{\\theta_0}}\\\\[0.2cm]\\frac{\\partial{J}}{\\partial{\\theta_1}}\\end{array}\\right]\n",
    "= \\frac{\\partial{J}(\\Theta)}{\\partial{\\Theta}}\n",
    "$$\n",
    "\n",
    "La transposée de $X$ est une matrice $(n+1, m)$ qu'on multiplie avec un membre de dimension $(m,1)$ pour obtenir donc les $(n+1)$ équations donnant les paramètres $\\Theta$ recherchés.\n",
    "\n",
    "Pour ce cas simple, on donne le sentiment d'avoir dérivé une fonction par rapport à un vecteur. Mais attention, la fonction $J(X,\\Theta)$ donne un scalaire, la dérivée partielle par rapport au vecteur $\\Theta$ est le gradient de $J$ par rapport à $\\Theta$, $\\displaystyle \\quad \\frac{\\partial J}{\\partial \\Theta}\\quad $ qui est donc un vecteur. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode de descente du gradient vue plus haut pourra aussi s'écrire sous forme matricielle de la façon suivante.\n",
    "$$ \\Theta \\leftarrow \\Theta -\\alpha \\frac{\\partial{J}}{\\partial{\\Theta}}$$\n",
    "\n",
    "Le cahier suivant donnera un exemple d'application en Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Généralisation à une régression polynomiale\n",
    "\n",
    "On peut penser a priori que la régression linéaire est finalement d'une application restreinte et que beaucoup de problème ne peuvent pas s'y adapter. Mais en fait, nous allons montrer ici qu'on peut généraliser simplement la méthode de la régression linéaire à des problèmes de régression polynomiale. Ceci est particulièrement intéressant, car les fonctions continues et dérivables (suffisamment de fois) peuvent être approximées par des polynômes (voir les [développements de Taylor](https://fr.wikipedia.org/wiki/Th%C3%A9or%C3%A8me_de_Taylor)). On pourra continuer à utiliser les formes matricielles que nous avons vues.\n",
    "\n",
    "Dans la section précédente, nous avons vu que nous nous étions ramené à cette opération matricielle.\n",
    "\n",
    "$$ F = X\\circ \\Theta $$\n",
    "\n",
    "Mais maintenant nous voulons résoudre avec une modèle de la forme: $\\quad f(x) = ax^2 + bx +c$\n",
    "\n",
    "Je recommande la lecture de l'excellente [vidéo](https://www.youtube.com/watch?v=8Y3r7F47Xfo&list=PLO_fdPEVlfKqUF5BPKjGSh7aV9aBshrpY&index=6)).\n",
    "\n",
    "Le résultat est simplement qu'on peut toujours résoudre avec la même forme $ F = X \\circ \\Theta $.\n",
    "\n",
    "Il suffit de poser:\n",
    "\n",
    "$$ \n",
    "X \\circ \\Theta \\quad = \\quad \n",
    "\\left[\\begin{array}{ccc} x^{(1)2} & x^{(1)} & 1\\\\ \\vdots \\\\ x^{(n)2} & x^{(n)} & 1\\\\ \\end{array}\\right]\n",
    "\\;\\circ\\;\n",
    "\\left[\\begin{array}{c} a \\\\ b \\\\ c \\\\\\end{array}\\right]\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation de l'échantillon\n",
    "\n",
    "Il peut y a avoir plusieurs pré-traitement à faire à un échantillon. On voit bien que si nos courbes de niveau vues plus haut sont complètement déformées avec une caractéristiques ayant des valeurs d'un tout autre ordre de grandeur que l'autre, on risque d'égarer la recherche.\n",
    "\n",
    "Pour éviter aussi les cas particuliers ou les deux paramètres auraient des ordres de grandeur totalement différent, on peut aussi normaliser les données $(x_i)_i$ et $(y_i)_i$. Cela se ferait de la manière suivante."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le module Scikit learn propose la commande [normalize](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html#sklearn.preprocessing.normalize) pour faire cette normalisation directement."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Évaluer la convergence de la méthode\n",
    "\n",
    "Dans les applications numériques qui suivent, nous verrons comment présenter une courbe qui montre la vitesse de convergence de la solution. Ceci sert en particulier pendant la recherche des bons paramètres qui font converger ou non la méthode du gradient (le nombre de pas et la vitesse de descente).\n",
    "\n",
    "Il existe aussi un coefficient dit de détermination qui a la forme suivante.\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum \\big(y-f(x)\\big)^2}{\\sum (y - \\overline{x})^2}$$\n",
    "\n",
    "Il donne aussi une vision synthétique de la qualité de notre modélisation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
