{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction d'un neurone\n",
    "\n",
    "On commence par construire un neurone simple, qu'on va ensuite tester. Je commance par l'exemple donné par [Miximum](https://www.miximum.fr/blog/introduction-au-deep-learning-1/) qui est basé sur des nombres aléatoires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition de la fonction Sigmoïde qui sera utilisée à l'intérieur de chaque neurone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le neurone, nous allons utiliser une classe définissant un objet neurone, qui aura un constructeur (nommé classiquement `__init__`) et une méthode d'activation. Cette méthode correspond au moment où le neurone reçoit des signaux des neurones qui lui sont connectés en amont. Le neurone pondère ces signaux (ici de manière aléatoire) et renvoie son signal qui sera donc capté par les neurones qui lui sont liés en aval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, input_size):\n",
    "        \"\"\"Initialisation des poids / biais avec des valeurs aléatoires.\"\"\"\n",
    "        self.weights = np.random.randn(input_size)\n",
    "        self.bias = np.random.randn()\n",
    "        \n",
    "    def activation(self, X):\n",
    "        \"\"\"On suppose que X est de la taille passée dans le constructeur.\"\"\"\n",
    "        aggregation = np.sum(X * self.weights) + self.bias\n",
    "        return sigmoid(aggregation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant tester ce neurone. Nous construisons une premier couche appelée `Input` qui est vecteur de `n` valeurs dont les 5 premières sont à 1 et les autres à 0 (voir le fichier [01_numpy](../02_std_ext/01_numpy.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "nb_zeros = 5\n",
    "Uns = np.zeros(nb_zeros)\n",
    "Zeros = np.ones(n - nb_zeros)\n",
    "Input =  np.concatenate((Uns, Zeros))\n",
    "Input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je construis maintenant mon neurone avec la classe définit précédement. Je me souviens que pour cela, le constructeur `__init__` demande de donner le nombre de neurones connectés en amont, donc ici mes `n` entrées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6987834466431921"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mon_neurone = Neuron(n)\n",
    "\n",
    "mon_neurone.activation(Input)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction d'un autre neurone"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "La distribution de poids de manière aléatoire ne me conviens pas et je veux donc pouvoir entrer des poids à mon neurone, à l'initialisation, mais aussi plus tard. Je rentrerai ces poids sous formes de vecteur et je n'ai plus besoin de rentrer une taille, car il s'agit simplement de la taille du vecteur des poids.\n",
    "\n",
    "Je modifie donc mon programme de la manière suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron2:\n",
    "    def __init__(self, input_weights):\n",
    "        \"\"\"Initialisation des poids / biais avec des valeurs aléatoires.\"\"\"\n",
    "        self.weights = input_weights\n",
    "        \n",
    "    def activation(self, X):\n",
    "        \"\"\"On suppose que X est de la taille passée dans le constructeur.\"\"\"\n",
    "        aggregation = np.sum(X * self.weights)\n",
    "        return sigmoid(aggregation)\n",
    "    \n",
    "    def update_weights(self, input_weights):\n",
    "        \"\"\" mise à jour des poids \"\"\"\n",
    "        self.weights = input_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser mon neurone, il me faut toujours mon vecteur d'entrée `Input` mais aussi maintenant un vecteur contenant les poids à attacher à chaque entrée, je l'appelerai `Weight`. Je commence avec des poids égaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weight = np.ones(n)\n",
    "Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933071490757153"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mon_neurone2 = Neuron2(Weight)\n",
    "\n",
    "mon_neurone2.activation(Input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si je bouleverse mes poids en mettant certains à zéro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_zeros = 3\n",
    "Zeros = np.zeros(nb_zeros)\n",
    "Uns = np.ones(n - nb_zeros)\n",
    "Weight =  np.concatenate((Uns, Zeros), axis=0)\n",
    "Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8807970779778823"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mon_neurone2.update_weights(Weight)\n",
    "\n",
    "mon_neurone2.activation(Input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pas de chance, je dégrade ici ma lecture."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
